{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11898dcd-3c00-4001-9d45-b1679ca463db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data: Customer reviews\n",
    "data = {\n",
    "    'review': [\n",
    "        'I love this product!',\n",
    "        'This is the worst product I have ever bought.',\n",
    "        'Great quality and fast delivery.',\n",
    "        'Not worth the money.',\n",
    "        'Highly recommend this product.'\n",
    "    ],\n",
    "    'sentiment': ['positive', 'negative', 'positive', 'negative', 'positive']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e32dfe-5e8d-4d5e-aa91-caa3d0187ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the DataFrame\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "print(df[['review', 'cleaned_review']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8373f72-b771-479c-bf6d-ca78d7428882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Convert text data to numerical features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_review'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select the logistic regression model\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1acab3-0cb6-4b32-9eaf-b835ffa9df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f8aac-70e6-4201-a462-7ec2b3bd5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20dbc69-4b96-4e59-a9db-dd6c70329068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "\n",
    "# Save the model and vectorizer\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "# Create a Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model and vectorizer\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "with open('vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Define the prediction endpoint\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json['review']\n",
    "    cleaned_review = preprocess_text(data)\n",
    "    X = vectorizer.transform([cleaned_review])\n",
    "    prediction = model.predict(X)\n",
    "    return jsonify({'sentiment': prediction[0]})\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688089a-ed6d-44ae-83b2-07750e14c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from azureml.core import Workspace, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "# Load the workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Register the model\n",
    "model = Model.register(workspace=ws, model_path='model.pkl', model_name='sentiment_analysis_model')\n",
    "\n",
    "# Deploy the model as a web service\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "service = Model.deploy(workspace=ws, name='sentiment-analysis-service', models=[model], inference_config=None, deployment_config=aci_config)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "# Test the deployed service\n",
    "print(service.scoring_uri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
